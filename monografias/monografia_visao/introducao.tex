%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   Introdução
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\chapter{Introdução}

Existem alguns tipos de ambiente que são inóspitos ao homem. Nesses casos é comum utilizar robôs para explorar e atuar em tais locais. A movimentação desses robôs pode ser automática (agentes autônomos), semi-automática (agentes semi-autônomos) ou manual. Neste trabalho, serão apresentados os passos para a construção de um \textit{toolkit Open Source} , de nome Horus, utilizado para o desenvolvimento e controle de aplicações que envolvam agentes inteligentes, com foco em dois problemas centrais. O primeiro problema refere-se à movimentação autônoma de um agente inteligente em ambientes desconhecidos. O segundo problema refere-se á  visão computacional, onde o agente deve ser capaz de extrair informações do ambiente através da utilização de câmeras virtuais ou reais.

Um Agente, por definição, é todo elemento ou entidade autônoma que pode perceber seu ambiente, por algum meio cognitivo ou sensorial, e de agir sobre esse ambiente por intermédio de atuadores. Podem-se citar como exemplos de agentes inteligentes, além de robôs autônomos ou semi-autônomos, personagens de um jogo, agentes de busca e recuperação de informação, entre outros.

Para que um agente autônomo seja capaz de atuar em um ambiente desconhecido é necessário anteriormente explorar esse local. Essa exploração pode ser feita através de um mapeamento desse ambiente. A forma como se mapeia o ambiente internamente no sistema é determinante na sua precisão e performance. As diferentes abordagens para controle de agentes móveis autônomos interagem fortemente com a representação do ambiente. Uma proposta para o mapeamento do ambiente, ainda não implementada no Horus, consiste na construção de um ambiente virtual 3D associado a um ambiente real no qual um robô real está explorando. Essa abordagem exige que o agente reconheça padrões no ambiente explorado e represente-os no ambiente virtual. 

 Durante a exploração do ambiente nos simuladores construídos, o agente deverá ser capaz de estimar sua posição local para localizar-se globalmente e se recuperar de possíveis erros de localização. Um correto mapeamento do ambiente junto a aplicação correta das leis da cinemática pode resolver tal problema. Uma proposta para a localização de um agente no ambiente é a utilização do método Monte Carlo \cite{FOX1999} ou do método SLAM (\textit{Simultaneous Location and Mapping}) \cite{Davison2004}, \cite{Dellaert2005}. O método selecionado para ser implementado no \textit{toolkit} Horus foi o SLAM.

 Um agente explora um ambiente através de sensores. O sensoriamento provê ao robô as informações necessárias para a construção de uma representação do ambiente onde está inserido e para uma interação com os elementos contidos nesse. Sistemas com uma variedade de sensores tendem a obter resultados mais precisos. A fusão de dados de sensores, ou como é mais conhecida, fusão de sensores, é o processo de combinação de dados de múltiplos sensores para estimar ou predizer estados dos elementos da cena. Neste trabalho, foram utilizados lasers, câmeras e odômetro como sensores.

 Para simular a visão de um agente inteligente, são utilizadas câmeras virtuais. Na abordagem desse trabalho, a visão é a principal forma de percepção do ambiente. A visão possibilita reconhecer padrões e classificar obstáculos.
Existem diferentes tipos de obstáculos. Estes podem ser classificados como transponível (aquele que não interrompe a trajetória), intransponível (aquele que o exigirá recalcular a trajetória por outro caminho) e redutor (aquele que permite o robô seguir pela trajetória, porém a uma velocidade mais lenta). Mesmo mediante a obstáculos transponíveis e redutores, pode ser conveniente recalcular o caminho devido ao aumento do custo do percurso. Uma proposta para o desvio de trajetória é o modelo baseado em Campos Potenciais proposto por [8]. A classificação de um obstáculo ocorre mediante a algum método de reconhecimento de padrões, baseado em visão computacional.

O \textit{toolkit} Horus, criado neste trabalho, propõe uma coleção de classes e algoritmos voltados a resolução de problemas pertencentes as áreas de visão computacional e mapeamento automático de ambientes. Nessa monografia, será dado foco à parte de visão computacional do Horus. De forma a validar a implementação desse \textit{toolkit} e demonstrar a sua utilidade, foram desenvolvidas três aplicações distintas: Os simuladores Teseu e Ariadnes, e o PyANPR. Neste trabalho, além do \textit{toolkit} Horus, serão, também, apresentados a parte de visão computacional utilizada no simulador Ariadnes e a aplicação para reconhecimento automático de placas de automóveis PyANPR.
